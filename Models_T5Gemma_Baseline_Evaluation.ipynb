{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Eyeball Samples\n",
        "\n",
        "### Story: DR. KOMETEVSKY'S DAY\n",
        "#### By FRITZ LEIBER"
      ],
      "metadata": {
        "id": "MI52o9aNnFpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "story = \"\"\"\n",
        "DR. KOMETEVSKY'S DAY\n",
        "\n",
        "\n",
        " By FRITZ LEIBER\n",
        "\n",
        " Illustrated by DAVID STONE\n",
        "\n",
        " [Transcriber's Note: This etext was produced from Galaxy Science Fiction February 1952. Extensive research did not uncover any evidence that the U.S. copyright on this publication was renewed.]\n",
        "\n",
        "\n",
        "\n",
        " Before science, there was superstition. After science, there will be ... what? The biggest, most staggering , most final fact of them all!\n",
        "\n",
        "\n",
        "\n",
        " \"But it's all predicted here! It even names this century for the next reshuffling of the planets.\"\n",
        "\n",
        " Celeste Wolver looked up unwillingly at the book her friend Madge Carnap held aloft like a torch. She made out the ill-stamped title, The Dance of the Planets . There was no mistaking the time of its origin; only paper from the Twentieth Century aged to that particularly nasty shade of brown. Indeed, the book seemed to Celeste a brown old witch resurrected from the Last Age of Madness to confound a world growing sane, and she couldn't help shrinking back a trifle toward her husband Theodor.\n",
        "\n",
        " He tried to come to her rescue. \"Only predicted in the vaguest way. As I understand it, Kometevsky claimed, on the basis of a lot of evidence drawn from folklore, that the planets and their moons trade positions every so often.\"\n",
        "\n",
        " \"As if they were playing Going to Jerusalem, or musical chairs,\" Celeste chimed in, but she couldn't make it sound funny.\n",
        "\n",
        " \"Jupiter was supposed to have started as the outermost planet, and is to end up in the orbit of Mercury,\" Theodor continued. \"Well, nothing at all like that has happened.\"\n",
        "\n",
        " \"But it's begun,\" Madge said with conviction. \"Phobos and Deimos have disappeared. You can't argue away that stubborn little fact.\"\n",
        "\n",
        " That was the trouble; you couldn't. Mars' two tiny moons had simply vanished during a period when, as was generally the case, the eyes of astronomy weren't on them. Just some hundred-odd cubic miles of rock—the merest cosmic flyspecks—yet they had carried away with them the security of a whole world.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Looking at the lovely garden landscape around her, Celeste Wolver felt that in a moment the shrubby hills would begin to roll like waves, the charmingly aimless paths twist like snakes and sink in the green sea, the sparsely placed skyscrapers dissolve into the misty clouds they pierced.\n",
        "  People must have felt like this , she thought, when Aristarches first hinted and Copernicus told them that the solid Earth under their feet was falling dizzily through space. Only it's worse for us, because they couldn't see that anything had changed. We can.\n",
        "\n",
        "\n",
        " \"You need something to cling to,\" she heard Madge say. \"Dr. Kometevsky was the only person who ever had an inkling that anything like this might happen. I was never a Kometevskyite before. Hadn't even heard of the man.\"\n",
        "\n",
        " She said it almost apologetically. In fact, standing there so frank and anxious-eyed, Madge looked anything but a fanatic, which made it much worse.\n",
        "\n",
        " \"Of course, there are several more convincing alternate explanations....\" Theodor began hesitantly, knowing very well that there weren't. If Phobos and Deimos had suddenly disintegrated, surely Mars Base would have noticed something. Of course there was the Disordered Space Hypothesis, even if it was little more than the chance phrase of a prominent physicist pounded upon by an eager journalist. And in any case, what sense of security were you left with if you admitted that moons and planets might explode, or drop through unseen holes in space? So he ended up by taking a different tack: \"Besides, if Phobos and Deimos simply shot off somewhere, surely they'd have been picked up by now by 'scope or radar.\"\n",
        "\n",
        " \"Two balls of rock just a few miles in diameter?\" Madge questioned.\n",
        "\"Aren't they smaller than many of the asteroids? I'm no astronomer, but I think' I'm right.\"\n",
        "\n",
        " And of course she was.\n",
        "\n",
        " She swung the book under her arm. \"Whew, it's heavy,\" she observed, adding in slightly scandalized tones, \"Never been microfilmed.\" She smiled nervously and looked them up and down. \"Going to a party?\" she asked.\n",
        "\n",
        " Theodor's scarlet cloak and Celeste's green culottes and silver jacket justified the question, but they shook their heads.\n",
        "\n",
        " \"Just the normally flamboyant garb of the family,\" Celeste said, while Theodor explained, \"As it happens, we're bound on business connected with the disappearance. We Wolvers practically constitute a sub-committee of the Congress for the Discovery of New Purposes. And since a lot of varied material comes to our attention, we're going to see if any of it correlates with this bit of astronomical sleight-of-hand.\"\n",
        "\n",
        " Madge nodded. \"Give you something to do, at any rate. Well, I must be off. The Buddhist temple has lent us their place for a meeting.\" She gave them a woeful grin. \"See you when the Earth jumps.\"\n",
        "\n",
        " Theodor said to Celeste, \"Come on, dear. We'll be late.\"\n",
        "\n",
        " But Celeste didn't want to move too fast. \"You know, Teddy,\" she said uncomfortably, \"all this reminds me of those old myths where too much good fortune is a sure sign of coming disaster. It was just too much luck, our great-grandparents missing World III and getting the World Government started a thousand years ahead of schedule. Luck like that couldn't last, evidently. Maybe we've gone too fast with a lot of things, like space-flight and the Deep Shaft and—\" she hesitated a bit—\"complex marriages. I'm a woman. I want complete security. Where am I to find it?\"\n",
        "\n",
        " \"In me,\" Theodor said promptly.\n",
        "\n",
        " \"In you?\" Celeste questioned, walking slowly. \"But you're just one-third of my husband. Perhaps I should look for it in Edmund or Ivan.\"\n",
        "\n",
        " \"You angry with me about something?\"\n",
        "\n",
        " \"Of course not. But a woman wants her source of security whole. In a crisis like this, it's disturbing to have it divided.\"\n",
        "\n",
        " \"Well, we are a whole and, I believe, indivisible family,\" Theodor told her warmly. \"You're not suggesting, are you, that we're going to be punished for our polygamous sins by a cosmic catastrophe? Fire from Heaven and all that?\"\n",
        "\n",
        " \"Don't be silly. I just wanted to give you a picture of my feeling.\" Celeste smiled. \"I guess none of us realized how much we've come to depend on the idea of unchanging scientific law. Knocks the props from under you.\"\n",
        "\n",
        " Theodor nodded emphatically. \"All the more reason to get a line on what's happening as quickly as possible. You know, it's fantastically far-fetched, but I think the experience of persons with Extra-Sensory Perception may give us a clue. During the past three or four days there's been a remarkable similarity in the dreams of ESPs all over the planet. I'm going to present the evidence at the meeting.\"\n",
        "\n",
        " Celeste looked up at him. \"So that's why Rosalind's bringing Frieda's daughter?\"\n",
        "\n",
        " \"Dotty is your daughter, too, and Rosalind's,\" Theodor reminded her.\n",
        "\n",
        " \"No, just Frieda's,\" Celeste said bitterly. \"Of course you may be the father. One-third of a chance.\"\n",
        "\n",
        " Theodor looked at her sharply, but didn't comment. \"Anyway, Dotty will be there,\" he said. \"Probably asleep by now. All the ESPs have suddenly seemed to need more sleep.\"\n",
        "\n",
        " As they talked, it had been growing darker, though the luminescence of the path kept it from being bothersome. And now the cloud rack parted to the east, showing a single red planet low on the horizon.\n",
        "\n",
        " \"Did you know,\" Theodor said suddenly, \"that in Gulliver's Travels Dean Swift predicted that better telescopes would show Mars to have two moons? He got the sizes and distances and periods damned accurately, too. One of the few really startling coincidences of reality and literature.\"\n",
        "\n",
        " \"Stop being eerie,\" Celeste said sharply. But then she went on, \"Those names Phobos and Deimos—they're Greek, aren't they? What do they mean?\"\n",
        "\n",
        " Theodor lost a step. \"Fear and Terror,\" he said unwillingly. \"Now don't go taking that for an omen. Most of the mythological names of major and minor ancient gods had been taken—the bodies in the Solar System are named that way, of course—and these were about all that were available.\"\n",
        "\n",
        " It was true, but it didn't comfort him much.\n",
        "\n",
        "\n",
        "\n",
        "  I am a God , Dotty was dreaming, and I want to be by myself and think. I and my god-friends like to keep some of our thoughts secret, but the other gods have forbidden us to.\n",
        "\n",
        "\n",
        " A little smile flickered across the lips of the sleeping girl, and the woman in gold tights and gold-spangled jacket leaned forward thoughtfully. In her dignity and simplicity and straight-spined grace, she was rather like a circus mother watching her sick child before she went out for the trapeze act.\n",
        "  I and my god-friends sail off in our great round silver boats , Dotty went on dreaming. The other gods are angry and scared. They are frightened of the thoughts we may think in secret. They follow us to hunt us down. There are many more of them than of us.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " As Celeste and Theodor entered the committee room, Rosalind Wolver—a glitter of platinum against darkness—came in through the opposite door and softly shut it behind her. Frieda, a fair woman in blue robes, got up from the round table.\n",
        "\n",
        " Celeste turned away with outward casualness as Theodor kissed his two other wives. She was pleased to note that Edmund seemed impatient too. A figure in close-fitting black, unrelieved except for two red arrows at the collar, he struck her as embodying very properly the serious, fateful temper of the moment.\n",
        "\n",
        " He took two briefcases from his vest pocket and tossed them down on the table beside one of the microfilm projectors.\n",
        "\n",
        " \"I suggest we get started without waiting for Ivan,\" he said.\n",
        "\n",
        " Frieda frowned anxiously. \"It's ten minutes since he phoned from the Deep Space Bar to say he was starting right away. And that's hardly a two minutes walk.\"\n",
        "\n",
        " Rosalind instantly started toward the outside door.\n",
        "\n",
        " \"I'll check,\" she explained. \"Oh, Frieda, I've set the mike so you'll hear if Dotty calls.\"\n",
        "\n",
        " Edmund threw up his hands. \"Very well, then,\" he said and walked over, switched on the picture and stared out moodily.\n",
        "\n",
        " Theodor and Frieda got out their briefcases, switched on projectors, and began silently checking through their material.\n",
        "\n",
        " Celeste fiddled with the TV and got a newscast. But she found her eyes didn't want to absorb the blocks of print that rather swiftly succeeded each other, so, after a few moments, she shrugged impatiently and switched to audio.\n",
        "\n",
        " At the noise, the others looked around at her with surprise and some irritation, but in a few moments they were also listening.\n",
        "\n",
        " \"The two rocket ships sent out from Mars Base to explore the orbital positions of Phobos and Deimos—that is, the volume of space they'd be occupying if their positions had remained normal—report finding masses of dust and larger debris. The two masses of fine debris are moving in the same orbits and at the same velocities as the two vanished moons, and occupy roughly the same volumes of space, though the mass of material is hardly a hundredth that of the moons. Physicists have ventured no statements as to whether this constitutes a confirmation of the Disintegration Hypothesis.\n",
        "\n",
        " \"However, we're mighty pleased at this news here. There's a marked lessening of tension. The finding of the debris—solid, tangible stuff—seems to lift the whole affair out of the supernatural miasma in which some of us have been tempted to plunge it. One-hundredth of the moons has been found.\n",
        "\n",
        " \"The rest will also be!\"\n",
        "\n",
        " Edmund had turned his back on the window. Frieda and Theodor had switched off their projectors.\n",
        "\n",
        " \"Meanwhile, Earthlings are going about their business with a minimum of commotion, meeting with considerable calm the strange threat to the fabric of their Solar System. Many, of course, are assembled in churches and humanist temples. Kometevskyites have staged helicopter processions at Washington, Peking, Pretoria, and Christiana, demanding that instant preparations be made for—and I quote—'Earth's coming leap through space.' They have also formally challenged all astronomers to produce an explanation other than the one contained in that strange book so recently conjured from oblivion, The Dance of the Planets .\n",
        "\n",
        " \"That about winds up the story for the present. There are no new reports from Interplanetary Radar, Astronomy, or the other rocket ships searching in the extended Mars volume. Nor have any statements been issued by the various groups working on the problem in Astrophysics, Cosmic Ecology, the Congress for the Discovery of New Purposes, and so forth. Meanwhile, however, we can take courage from the words of a poem written even before Dr. Kometevsky's book:\n",
        "\n",
        " \"This Earth is not the steadfast place\n",
        " We landsmen build upon;\n",
        " From deep to deep she varies pace,\n",
        " And while she comes is gone.\n",
        " Beneath my feet I feel\n",
        " Her smooth bulk heave and dip;\n",
        " With velvet plunge and soft upreel\n",
        " She swings and steadies to her keel\n",
        " Like a gallant, gallant ship.\"\n",
        "\n",
        "\n",
        "\n",
        " While the TV voice intoned the poem, growing richer as emotion caught it up, Celeste looked around her at the others. Frieda, with her touch of feminine helplessness showing more than ever through her business-like poise. Theodor leaning forward from his scarlet cloak thrown back, smiling the half-smile with which he seemed to face even the unknown. Black Edmund, masking a deep uncertainty with a strong show of decisiveness.\n",
        "\n",
        " In short, her family. She knew their every quirk and foible. And yet now they seemed to her a million miles away, figures seen through the wrong end of a telescope.\n",
        "\n",
        " Were they really a family? Strong sources of mutual strength and security to each other? Or had they merely been playing family, experimenting with their notions of complex marriage like a bunch of silly adolescents? Butterflies taking advantage of good weather to wing together in a glamorous, artificial dance—until outraged Nature decided to wipe them out?\n",
        "\n",
        " As the poem was ending, Celeste saw the door open and Rosalind come slowly in. The Golden Woman's face was white as the paths she had been treading.\n",
        "\n",
        " Just then the TV voice quickened with shock. \"News! Lunar Observatory One reports that, although Jupiter is just about to pass behind the Sun, a good coronagraph of the planet has been obtained. Checked and rechecked, it admits of only one interpretation, which Lunar One feels duty-bound to release. Jupiter's fourteen moons are no longer visible! \"\n",
        "\n",
        " The chorus of remarks with which the Wolvers would otherwise have received this was checked by one thing: the fact that Rosalind seemed not to hear it. Whatever was on her mind prevented even that incredible statement from penetrating.\n",
        "\n",
        " She walked shakily to the table and put down a briefcase, one end of which was smudged with dirt.\n",
        "\n",
        " Without looking at them, she said, \"Ivan left the Deep Space Bar twenty minutes ago, said he was coming straight here. On my way back I searched the path. Midway I found this half-buried in the dirt. I had to tug to get it out—almost as if it had been cemented into the ground. Do you feel how the dirt seems to be in the leather, as if it had lain for years in the grave?\"\n",
        "\n",
        " By now the others were fingering the small case of microfilms they had seen so many times in Ivan's competent hands. What Rosalind said was true. It had a gritty, unwholesome feel to it. Also, it felt strangely heavy.\n",
        "\n",
        " \"And see what's written on it,\" she added.\n",
        "\n",
        " They turned it over. Scrawled with white pencil in big, hasty, frantic letters were two words:\n",
        "\n",
        " \"Going down!\"\n",
        "\n",
        "\n",
        "\n",
        "  The other gods , Dotty dreamt, are combing the whole Universe for us. We have escaped them many times, but now our tricks are almost used up. There are no doors going out of the Universe and our boats are silver beacons to the hunters. So we decide to disguise them in the only way they can be disguised. It is our last chance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Edmund rapped the table to gain the family's attention. \"I'd say we've done everything we can for the moment to find Ivan. We've made a thorough local search. A wider one, which we can't conduct personally, is in progress. All helpful agencies have been alerted and descriptions are being broadcast. I suggest we get on with the business of the evening—which may very well be connected with Ivan's disappearance.\"\n",
        "\n",
        " One by one the others nodded and took their places at the round table. Celeste made a great effort to throw off the feeling of unreality that had engulfed her and focus attention on her microfilms.\n",
        "\n",
        " \"I'll take over Ivan's notes,\" she heard Edmund say. \"They're mainly about the Deep Shaft.\"\n",
        "\n",
        " \"How far have they got with that?\" Frieda asked idly. \"Twenty-five miles?\"\n",
        "\n",
        " \"Nearer thirty, I believe,\" Edmund answered, \"and still going down.\"\n",
        "\n",
        " At those last two words they all looked up quickly. Then their eyes went toward Ivan's briefcase.\n",
        "\n",
        "\n",
        "\n",
        "  Our trick has succeeded , Dotty dreamt. The other gods have passed our hiding place a dozen times without noticing. They search the Universe for us many times in vain. They finally decide that we have found a door going out of the Universe. Yet they fear us all the more. They think of us as devils who will some day return through the door to destroy them. So they watch everywhere. We lie quietly smiling in our camouflaged boats, yet hardly daring to move or think, for fear that the faintest echoes of our doings will give them a clue. Hundreds of millions of years pass by. They seem to us no more than drugged hours in a prison.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Theodor rubbed his eyes and pushed his chair back from the table. \"We need a break.\"\n",
        "\n",
        " Frieda agreed wearily. \"We've gone through everything.\"\n",
        "\n",
        " \"Good idea,\" Edmund said briskly. \"I think we've hit on several crucial points along the way and half disentangled them from the great mass of inconsequential material. I'll finish up that part of the job right now and present my case when we're all a bit fresher. Say half an hour?\"\n",
        "\n",
        " Theodor nodded heavily, pushing up from his chair and hitching his cloak over a shoulder.\n",
        "\n",
        " \"I'm going out for a drink,\" he informed them.\n",
        "\n",
        " After several hesitant seconds, Rosalind quietly followed him. Frieda stretched out on a couch and closed her eyes. Edmund scanned microfilms tirelessly, every now and then setting one aside.\n",
        "\n",
        " Celeste watched him for a minute, then sprang up and started toward the room where Dotty was asleep. But midway she stopped.\n",
        "  Not my child , she thought bitterly. Frieda's her mother, Rosalind her nurse. I'm nothing at all. Just one of the husband's girl friends. A lady of uneasy virtue in a dissolving world.\n",
        "\n",
        "\n",
        " But then she straightened her shoulders and went on.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Rosalind didn't catch up with Theodor. Her footsteps were silent and he never looked back along the path whose feeble white glow rose only knee-high, lighting a low strip of shrub and mossy tree trunk to either side, no more.\n",
        "\n",
        " It was a little chilly. She drew on her gloves, but she didn't hurry. In fact, she fell farther and farther behind the dipping tail of his scarlet cloak and his plodding red shoes, which seemed to move disembodied, like those in the fairy tale.\n",
        "\n",
        " When she reached the point where she had found Ivan's briefcase, she stopped altogether.\n",
        "\n",
        " A breeze rustled the leaves, and, moistly brushing her cheek, brought forest scents of rot and mold. After a bit she began to hear the furtive scurryings and scuttlings of forest creatures.\n",
        "\n",
        " She looked around her half-heartedly, suddenly realizing the futility of her quest. What clues could she hope to find in this knee-high twilight? And they'd thoroughly combed the place earlier in the night.\n",
        "\n",
        " Without warning, an eerie tingling went through her and she was seized by a horror of the cold, grainy Earth underfoot—an ancestral terror from the days when men shivered at ghost stories about graves and tombs.\n",
        "\n",
        " A tiny detail persisted in bulking larger and larger in her mind—the unnaturalness of the way the Earth had impregnated the corner of Ivan's briefcase, almost as if dirt and leather co-existed in the same space. She remembered the queer way the partly buried briefcase had resisted her first tug, like a rooted plant.\n",
        "\n",
        " She felt cowed by the mysterious night about her, and literally dwarfed, as if she had grown several inches shorter. She roused herself and started forward.\n",
        "\n",
        " Something held her feet.\n",
        "\n",
        " They were ankle-deep in the path. While she looked in fright and horror, they began to sink still lower into the ground.\n",
        "\n",
        " She plunged frantically, trying to jerk loose. She couldn't. She had the panicky feeling that the Earth had not only trapped but invaded her; that its molecules were creeping up between the molecules of her flesh; that the two were becoming one.\n",
        "\n",
        " And she was sinking faster. Now knee-deep, thigh-deep, hip-deep, waist-deep. She beat at the powdery path with her hands and threw her body from side to side in agonized frenzy like some sinner frozen in the ice of the innermost circle of the ancients' hell. And always the sense of the dark, grainy tide rose inside as well as around her.\n",
        "\n",
        " She thought, he'd just have had time to scribble that note on his briefcase and toss it away. She jerked off a glove, leaned out as far as she could, and made a frantic effort to drive its fingers into the powdery path. Then the Earth mounted to her chin, her nose, and covered her eyes.\n",
        "\n",
        " She expected blackness, but it was as if the light of the path stayed with her, making a little glow all around. She saw roots, pebbles, black rot, worn tunnels, worms. Tier on tier of them, her vision penetrating the solid ground. And at the same time, the knowledge that these same sorts of things were coursing up through her.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " And still she continued to sink at a speed that increased, as if the law of gravitation applied to her in a diminished way. She dropped from black soil through gray clay and into pale limestone.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Her tortured, rock-permeated lungs sucked at rock and drew in air. She wondered madly if a volume of air were falling with her through the stone.\n",
        "\n",
        " A glitter of quartz. The momentary openness of a foot-high cavern with a trickle of water. And then she was sliding down a black basalt column, half inside it, half inside gold-flecked ore. Then just black basalt. And always faster.\n",
        "\n",
        " It grew hot, then hotter, as if she were approaching the mythical eternal fires.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " At first glance Theodor thought the Deep Space Bar was empty. Then he saw a figure hunched monkeylike on the last stool, almost lost in the blue shadows, while behind the bar, her crystal dress blending with the tiers of sparkling glasses, stood a grave-eyed young girl who could hardly have been fifteen.\n",
        "\n",
        " The TV was saying, \"... in addition, a number of mysterious disappearances of high-rating individuals have been reported. These are thought to be cases of misunderstanding, illusory apprehension, and impulse traveling—a result of the unusual stresses of the time. Finally, a few suggestible individuals in various parts of the globe, especially the Indian Peninsula, have declared themselves to be 'gods' and in some way responsible for current events.\n",
        "\n",
        " \"It is thought—\"\n",
        "\n",
        " The girl switched off the TV and took Theodor's order, explaining casually, \"Joe wanted to go to a Kometevskyite meeting, so I took over for him.\" When she had prepared Theodor's highball, she announced,\n",
        "\"I'll have a drink with you gentlemen,\" and squeezed herself a glass of pomegranate juice.\n",
        "\n",
        " The monkeylike figure muttered, \"Scotch-and-soda,\" then turned toward Edmund and asked, \"And what is your reaction to all this, sir?\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Theodor recognized the shrunken wrinkle-seamed face. It was Colonel Fortescue, a military antique long retired from the Peace Patrol and reputed to have seen actual fighting in the Last Age of Madness. Now, for some reason, the face sported a knowing smile.\n",
        "\n",
        " Theodor shrugged. Just then the TV \"big news\" light blinked blue and the girl switched on audio. The Colonel winked at Theodor.\n",
        "\n",
        " \"... confirming the disappearance of Jupiter's moons. But two other utterly fantastic reports have just been received. First, Lunar Observatory One says that it is visually tracking fourteen small bodies which it believes may be the lost moons of Jupiter. They are moving outward from the Solar System at an incredible velocity and are already beyond the orbit of Saturn!\"\n",
        "\n",
        " The Colonel said, \"Ah!\"\n",
        "\n",
        " \"Second, Palomar reports a large number of dark bodies approaching the Solar System at an equally incredible velocity. They are at about twice the distance of Pluto, but closing in fast! We will be on the air with further details as soon as possible.\"\n",
        "\n",
        " The Colonel said, \"Ah-ha!\"\n",
        "\n",
        " Theodor stared at him. The old man's self-satisfied poise was almost amusing.\n",
        "\n",
        " \"Are you a Kometevskyite?\" Theodor asked him.\n",
        "\n",
        " The Colonel laughed. \"Of course not, my boy. Those poor people are fumbling in the dark. Don't you see what's happened?\"\n",
        "\n",
        " \"Frankly, no.\"\n",
        "\n",
        " The Colonel leaned toward Theodor and whispered gruffly, \"The Divine Plan. God is a military strategist, naturally.\"\n",
        "\n",
        " Then he lifted the scotch-and-soda in his clawlike hand and took a satisfying swallow.\n",
        "\n",
        " \"I knew it all along, of course,\" he went on musingly, \"but this last news makes it as plain as a rocket blast, at least to anyone who knows military strategy. Look here, my boy, suppose you were commanding a fleet and got wind of the enemy's approach—what would you do? Why, you'd send your scouts and destroyers fanning out toward them. Behind that screen you'd mass your heavy ships. Then—\"\n",
        "\n",
        " \"You don't mean to imply—\" Theodor interrupted.\n",
        "\n",
        " The girl behind the bar looked at them both cryptically.\n",
        "\n",
        " \"Of course I do!\" the Colonel cut in sharply. \"It's a war between the forces of good and evil. The bright suns and planets are on one side, the dark on the other. The moons are the destroyers, Jupiter and Saturn are the big battleships, while we're on a heavy cruiser, I'm proud to say. We'll probably go into action soon. Be a corking fight, what? And all by divine strategy!\"\n",
        "\n",
        " He chuckled and took another big drink. Theodor looked at him sourly. The girl behind the bar polished a glass and said nothing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Dotty suddenly began to turn and toss, and a look of terror came over her sleeping face. Celeste leaned forward apprehensively.\n",
        "\n",
        " The child's lips worked and Celeste made out the sleepy-fuzzy words:\n",
        "\"They've found out where we're hiding. They're coming to get us. No! Please, no!\"\n",
        "\n",
        " Celeste's reactions were mixed. She felt worried about Dotty and at the same time almost in terror of her, as if the little girl were an agent of supernatural forces. She told herself that this fear was an expression of her own hostility, yet she didn't really believe it. She touched the child's hand.\n",
        "\n",
        " Dotty's eyes opened without making Celeste feel she had quite come awake. After a bit she looked at Celeste and her little lips parted in a smile.\n",
        "\n",
        " \"Hello,\" she said sleepily. \"I've been having such funny dreams.\" Then, after a pause, frowning, \"I really am a god, you know. It feels very queer.\"\n",
        "\n",
        " \"Yes, dear?\" Celeste prompted uneasily. \"Shall I call Frieda?\"\n",
        "\n",
        " The smile left Dotty's lips. \"Why do you act so nervous around me?\" she asked. \"Don't you love me, Mummy?\"\n",
        "\n",
        " Celeste started at the word. Her throat closed. Then, very slowly, her face broke into a radiant smile. \"Of course I do, darling. I love you very much.\"\n",
        "\n",
        " Dotty nodded happily, her eyes already closed again.\n",
        "\n",
        " There was a sudden flurry of excited voices beyond the door. Celeste heard her name called. She stood up.\n",
        "\n",
        " \"I'm going to have to go out and talk with the others,\" she said. \"If you want me, dear, just call.\"\n",
        "\n",
        " \"Yes, Mummy.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Edmund rapped for attention. Celeste, Frieda, and Theodor glanced around at him. He looked more frightfully strained, they realized, than even they felt. His expression was a study in suppressed excitement, but there were also signs of a knowledge that was almost too overpowering for a human being to bear.\n",
        "\n",
        " His voice was clipped, rapid. \"I think it's about time we stopped worrying about our own affairs and thought of those of the Solar System, partly because I think they have a direct bearing on the disappearances of Ivan end Rosalind. As I told you, I've been sorting out the crucial items from the material we've been presenting. There are roughly four of those items, as I see it. It's rather like a mystery story. I wonder if, hearing those four clues, you will come to the same conclusion I have.\"\n",
        "\n",
        " The others nodded.\n",
        "\n",
        " \"First, there are the latest reports from Deep Shaft, which, as you know, has been sunk to investigate deep-Earth conditions. At approximately twenty-nine miles below the surface, the delvers have encountered a metallic obstruction which they have tentatively named the durasphere. It resists their hardest drills, their strongest corrosives. They have extended a side-tunnel at that level for a quarter of a mile. Delicate measurements, made possible by the mirror-smooth metal surface, show that the durasphere has a slight curvature that is almost exactly equal to the curvature of the Earth itself. The suggestion is that deep borings made anywhere in the world would encounter the durasphere at the same depth.\n",
        "\n",
        " \"Second, the movements of the moons of Mars and Jupiter, and particularly the debris left behind by the moons of Mars. Granting Phobos and Deimos had duraspheres proportional in size to that of Earth, then the debris would roughly equal in amount the material in those two duraspheres' rocky envelopes. The suggestion is that the two duraspheres suddenly burst from their envelopes with such titanic velocity as to leave those disrupted envelopes behind.\"\n",
        "\n",
        " It was deadly quiet in the committee room.\n",
        "\n",
        " \"Thirdly, the disappearances of Ivan and Rosalind, and especially the baffling hint—from Ivan's message in one case and Rosalind's downward-pointing glove in the other—that they were both somehow drawn into the depths of the Earth.\n",
        "\n",
        " \"Finally, the dreams of the ESPs, which agree overwhelmingly in the following points: A group of beings separate themselves from a godlike and telepathic race because they insist on maintaining a degree of mental privacy. They flee in great boats or ships of some sort. They are pursued on such a scale that there is no hiding place for them anywhere in the universe. In some manner they successfully camouflage their ships. Eons pass and their still-fanatical pursuers do not penetrate their secret. Then, suddenly, they are detected.\"\n",
        "\n",
        " Edmund waited. \"Do you see what I'm driving at?\" he asked hoarsely.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " He could tell from their looks that the others did, but couldn't bring\n",
        " themselves to put it into words.\n",
        "\n",
        " \"I suppose it's the time-scale and the value-scale that are so hard for\n",
        " us to accept,\" he said softly. \"Much more, even, than the size-scale.\n",
        " The thought that there are creatures in the Universe to whom the whole\n",
        " career of Man—in fact, the whole career of life—is no more than a few\n",
        " thousand or hundred thousand years. And to whom Man is no more than a\n",
        " minor stage property—a trifling part of a clever job of camouflage.\"\n",
        "\n",
        " This time he went on, \"Fantasy writers have at times hinted all sorts\n",
        " of odd things about the Earth—that it might even be a kind of single\n",
        " living creature, or honeycombed with inhabited caverns, and so on.\n",
        " But I don't know that any of them have ever suggested that the Earth,\n",
        " together with all the planets and moons of the Solar System, might\n",
        " be....\"\n",
        "\n",
        " In a whisper, Frieda finished for him, \"... a camouflaged fleet of\n",
        " gigantic spherical spaceships.\"\n",
        "\n",
        " \" Your guess happens to be the precise truth. \"\n",
        "\n",
        " At that familiar, yet dreadly unfamiliar voice, all four of them swung\n",
        " toward the inner door. Dotty was standing there, a sleep-stupefied\n",
        " little girl with a blanket caught up around her and dragging behind.\n",
        " Their own daughter. But in her eyes was a look from which they cringed.\n",
        "\n",
        " She said, \"I am a creature somewhat older than what your geologists\n",
        " call the Archeozoic Era. I am speaking to you through a number of\n",
        " telepathically sensitive individuals among your kind. In each case my\n",
        " thoughts suit themselves to your level of comprehension. I inhabit the\n",
        " disguised and jetless spaceship which is your Earth.\"\n",
        "\n",
        " Celeste swayed a step forward. \"Baby....\" she implored.\n",
        "\n",
        " Dotty went on, without giving her a glance, \"It is true that we planted\n",
        " the seeds of life on some of these planets simply as part of our\n",
        " camouflage, just as we gave them a suitable environment for each. And\n",
        " it is true that now we must let most of that life be destroyed. Our\n",
        " hiding place has been discovered, our pursuers are upon us, and we must\n",
        " make one last effort to escape or do battle, since we firmly believe\n",
        " that the principle of mental privacy to which we have devoted our\n",
        " existence is perhaps the greatest good in the whole Universe.\n",
        "\n",
        " \"But it is not true that we look with contempt upon you. Our whole race\n",
        " is deeply devoted to life, wherever it may come into being, and it is\n",
        " our rule never to interfere with its development. That was one of\n",
        " the reasons we made life a part of our camouflage—it would make our\n",
        " pursuers reluctant to examine these planets too closely.\n",
        "\n",
        " \"Yes, we have always cherished you and watched your evolution with\n",
        " interest from our hidden lairs. We may even unconsciously have shaped\n",
        " your development in certain ways, trying constantly to educate you away\n",
        " from war and finally succeeding—which may have given the betraying\n",
        " clue to our pursuers.\n",
        "\n",
        " \"Your planets must be burst asunder—this particular planet in the\n",
        " area of the Pacific—so that we may have our last chance to escape.\n",
        " Even if we did not move, our pursuers would destroy you with us. We\n",
        " cannot invite you inside our ships—not for lack of space, but because\n",
        " you could never survive the vast accelerations to which you would be\n",
        " subjected. You would, you see, need very special accommodations, of\n",
        " which we have enough only for a few.\n",
        "\n",
        " \"Those few we will take with us, as the seed from which a new human\n",
        " race may—if we ourselves somehow survive—be born.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Rosalind and Ivan stared dumbly at each other across the egg-shaped\n",
        " silver room, without apparent entrance or exit, in which they were\n",
        " sprawled. But their thoughts were no longer of thirty-odd mile\n",
        " journeys down through solid earth, or of how cool it was after the\n",
        " heat of the passage, or of how grotesque it was to be trapped here,\n",
        " the fragment of a marriage. They were both listening to the voice that\n",
        " spoke inside their minds.\n",
        "\n",
        " \"In a few minutes your bodies will be separated into layers one atom\n",
        " thick, capable of being shelved or stored in such a way as to endure\n",
        " almost infinite accelerations. Single cells will cover acres of space.\n",
        " But do not be alarmed. The process will be painless and each particle\n",
        " will be catalogued for future assembly. Your consciousness will endure\n",
        " throughout the process.\"\n",
        "\n",
        " Rosalind looked at her gold-shod toes. She was wondering, will they go\n",
        " first, or my head? Or will I be peeled like an apple?\n",
        "\n",
        "\n",
        " She looked at Ivan and knew he was thinking the same thing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Up in the committee room, the other Wolvers slumped around the table.\n",
        " Only little Dotty sat straight and staring, speechless and unanswering,\n",
        " quite beyond their reach, like a telephone off the hook and with the\n",
        " connection open, but no voice from the other end.\n",
        "\n",
        " They had just switched off the TV after listening to a confused\n",
        " medley of denials, prayers, Kometevskyite chatterings, and a few\n",
        " astonishingly realistic comments on the possibility of survival.\n",
        "\n",
        " These last pointed out that, on the side of the Earth opposite the\n",
        " Pacific, the convulsions would come slowly when the entombed spaceship\n",
        " burst forth—provided, as seemed the case, that it moved without jets\n",
        " or reaction.\n",
        "\n",
        " It would be as if the Earth's vast core simply vanished. Gravity would\n",
        " diminish abruptly to a fraction of its former value. The empty envelope\n",
        " of rock and water and air would slowly fall together, though at the\n",
        " same time the air would begin to escape from the debris because there\n",
        " would no longer be the mass required to hold it.\n",
        "\n",
        " However, there might be definite chances of temporary and even\n",
        " prolonged survival for individuals in strong, hermetically sealed\n",
        " structures, such as submarines and spaceships. The few spaceships on\n",
        " Earth were reported to have blasted off, or be preparing to leave, with\n",
        " as many passengers as could be carried.\n",
        "\n",
        " But most persons, apparently, could not contemplate action of any sort.\n",
        " They could only sit and think, like the Wolvers.\n",
        "\n",
        " A faint smile relaxed Celeste's face. She was thinking, how beautiful!\n",
        " It means the death of the Solar System, which is a horrifying\n",
        " subjective concept. Objectively, though, it would be a more awesome\n",
        " sight than any human being has ever seen or ever could see. It's an\n",
        " absurd and even brutal thing to wish—but I wish I could see the whole\n",
        " cataclysm from beginning to end. It would make death seem very small, a\n",
        " tiny personal event.\n",
        "\n",
        "\n",
        " Dotty's face was losing its blank expression, becoming intent and\n",
        " alarmed.\n",
        "\n",
        " \"We are in contact with our pursuers,\" she said in the\n",
        " familiar-unfamiliar voice. \"Negotiations are now going on. There\n",
        " seems to be—there is a change in them. Where they were harsh and\n",
        " vindictive before, they now are gentle and conciliatory.\" She paused,\n",
        " the alarm on her childish features pinching into anxious uncertainty.\n",
        "\"Our pursuers have always been shrewd. The change in them may be false,\n",
        " intended merely to lull us into allowing them to come close enough to\n",
        " destroy us. We must not fall into the trap by growing hopeful....\"\n",
        "\n",
        " They leaned forward, clutching hands, watching the little face as\n",
        " though it were a television screen. Celeste had the wild feeling that\n",
        " she was listening to a communique from a war so unthinkably vast and\n",
        " violent, between opponents so astronomically huge and nearly immortal,\n",
        " that she felt like no more than a reasoning ameba ... and then realized\n",
        " with an explosive urge to laugh that that was exactly the situation.\n",
        "\n",
        " \"No!\" said Dotty. Her eyes began to glow. \"They have changed! During\n",
        " the eons in which we lay sealed away and hidden from them, knowing\n",
        " nothing of them, they have rebelled against the tyranny of a communal\n",
        " mind to which no thoughts are private ... the tyranny that we ourselves\n",
        " fled to escape. They come not to destroy us, but to welcome us back to\n",
        " a society that we and they can make truly great!\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Frieda collapsed to a chair, trembling between laughter and hysterical\n",
        " weeping. Theodor looked as blank as Dotty had while waiting for words\n",
        " to speak. Edmund sprang to the picture window, Celeste toward the TV\n",
        " set.\n",
        "\n",
        " Climbing shakily out of the chair, Frieda stumbled to the picture\n",
        " window and peered out beside Edmund. She saw lights bobbing along the\n",
        " paths with a wild excitement.\n",
        "\n",
        " On the TV screen, Celeste watched two brightly lit ships spinning in\n",
        " the sky—whether human spaceships or Phobos and Deimos come to help\n",
        " Earth rejoice, she couldn't tell.\n",
        "\n",
        " Dotty spoke again, the joy in her strange voice forcing them to turn.\n",
        "\"And you, dear children, creatures of our camouflage, we welcome\n",
        " you—whatever your future career on these planets or like ones—into\n",
        " the society of enlightened worlds! You need not feel small and alone\n",
        " and helpless ever again, for we shall always be with you!\"\n",
        "\n",
        " The outer door opened. Ivan and Rosalind reeled in, drunkenly smiling,\n",
        " arm in arm.\n",
        "\n",
        " \"Like rockets,\" Rosalind blurted happily. \"We came through the\n",
        " durasphere and solid rock ... shot up right to the surface.\"\n",
        "\n",
        " \"They didn't have to take us along,\" Ivan added with a bleary grin.\n",
        "\"But you know that already, don't you? They're too good to let you live\n",
        " in fear, so they must have told you by now.\"\n",
        "\n",
        " \"Yes, we know,\" said Theodor. \"They must be almost godlike in their\n",
        " goodness. I feel ... calm.\"\n",
        "\n",
        " Edmund nodded soberly. \"Calmer than I ever felt before. It's knowing, I\n",
        " suppose, that—well, we're not alone.\"\n",
        "\n",
        " Dotty blinked and looked around and smiled at them all with a wholly\n",
        " little-girl smile.\n",
        "\n",
        " \"Oh, Mummy,\" she said, and it was impossible to tell whether she spoke\n",
        " to Frieda or Rosalind or Celeste, \"I've just had the funniest dream.\"\n",
        "\n",
        " \"No, darling,\" said Rosalind gently, \"it's we who had the dream. We've\n",
        " just awakened.\"\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "ltxcaX7rm_U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Picked one of the stories from the test set to eyeball the\n",
        "# output generated by the model for analysis. This code here\n",
        "# will remove all extra whitespace characters.\n",
        "story = \" \".join(story.split())"
      ],
      "metadata": {
        "id": "U6B1mGK4Io6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "# For Preprocessing\n",
        "!pip install -q -U datasets\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "from datasets import Dataset, load_dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install -q -U torch torchvision torchaudio fastai\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U transformers\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U tokenizers\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U evaluate\n",
        "!pip install -q -U rouge_score\n",
        "!pip install -q -U bert_score\n",
        "!pip install -q -U loralib einops xformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "pAHIvOeYeE9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30240325-77a0-487c-f43a-6a4d335f6370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    load_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model_name = \"t5gemma_baseline-2025-07-29_170029\"\n",
        "\n",
        "model_quantized = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    f\"/content/drive/MyDrive/DS266/project/models/{model_name}\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0})\n",
        "\n",
        "# Tokenizer was unchanged.\n",
        "tokenizer_quantized = AutoTokenizer.from_pretrained(\"google/t5gemma-2b-2b-ul2-it\")\n",
        "model_quantized = prepare_model_for_kbit_training(model_quantized)\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"k_proj\", \"v_proj\", \"q_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    modules_to_save=[\"lm_head\"]\n",
        ")\n",
        "\n",
        "model_quantized = get_peft_model(model_quantized, config)\n",
        "print(model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "923c3d5928d242cd949f7926ec013014",
            "6364fae64cf34a5b8f69e1bc82b870c3",
            "287457e817a6413f873f006a05e99781",
            "003c5692659c413d9fa84a677333b811",
            "1c6a8361b10542cc9af53a572b80aaee",
            "8d7e396f4e5d48e5a0bdd6e02635f768",
            "7a27c2be89d24c31af479338d740eb09",
            "613a5afc3529465caac6bf4d798d0960",
            "a1e5a784cf28457e9dc5f9a60772306a",
            "88fcf332ec58499fa69df325bd9baf8b",
            "f04de82c46994bb7bd939e8515c00b00",
            "096126afe7f744309bb8cc494be621d2",
            "f960321dca3c4e38b6b45deb27fa7f6f",
            "da5bf9e935e94713808c7574c2817c06",
            "98e3e340fdf54c9f862fd6677d8549be",
            "d403416c2fa04f7aa7a6597b8ee6aa6f",
            "4e87a717a67c407eb89ea816e37f6ee1",
            "bb44d6d2ae6341668fdbedb0f47ca20c",
            "64bcd09957474f5f9e99e292911b5ea1",
            "992446ef40b94f78a77c1e355148ed66",
            "e99f59457f66417ab405df1f5d5a72da",
            "7864d152d16445d8b6ad1f290e71ba8e",
            "9e6e91ce898a4eccb7a7957673f6d33d",
            "734c8e9e0d3a4f6ab3dd9b5a6fbc0cdb",
            "a218ac95d9b54a909885ec9627bfe793",
            "b11e3d8d32ba4ddb903d70cc3ab3dccf",
            "a23346dc957b4d308132e57d54891fcd",
            "39877d90f3134a57a52320adf3bcda30",
            "4d39b00ca2d945edb1c68988efd08531",
            "22bd7980adfe4a63a01a978868ceddc1",
            "10c05c98592042e4a976ec712dc17418",
            "c0b4841a938544b2889aaf10299e8276",
            "43a1ae2c32444837bac7984c0c52e64a",
            "5dba8f7fa74a4bd4b4ba77bc17dd48b5",
            "e248e94460d34fbfa3964562cdadabc1",
            "0cc3930aaa424395a97da124b07b56db",
            "678d4f107a634692a4b001953a24bbbb",
            "feb64fe6d64f4774aed422d2dba32139",
            "4ee838005c154b319a2744db94fc1a46",
            "9bb00e47f9694847a5e3872cbe91e632",
            "1a560650805d42a0af6d8a4ad6d0128f",
            "08d0e6fcc32a4c54824e6057101be20b",
            "f7ea774fc0244623bca0a3579acac098",
            "e183384d7dae4fa0b0682c379ea4905a",
            "ced5ffabe1ed4001a50105362cedc775",
            "f32471384d66457e96536376428bc9ea",
            "20483ce35be046bb97517b962d4ea3b9",
            "d12b7599a8ab4ca491df91fd4f027158",
            "0c035a62ebb44d4b991d3576690c4650",
            "612afba37b8f4b13ba9bc63380f6766e",
            "d0849d8bf4044053be14d9f4109b4d54",
            "8dcd041a0a9943a89b603d3802b23059",
            "565dc87edd9a44538b0ddc59fa431a62",
            "b4d6ba2608554dadb848e0804e75a7b6",
            "cc60c58eacd54f5bb50a5ec78d3be36a",
            "a8580181c50447ff83110d484e1cc783",
            "9e27ca05ceaf45cdaae05dc25133f2c2",
            "819b5866cd0a4bcd9a4ec8f51359d755",
            "deec86a959064563ae6fcbe7beb991d1",
            "00472c6c07ec4ecbaa043b8bc3ccba26",
            "31e1f3acb3864d00be85f1155bb63596",
            "d9c8699c4ff54b23ad9b82ed6c435b96",
            "d5d1e95a062b405096a2ab3f4f7bc548",
            "4e14ce126c554ddb8577c476fc105532",
            "a093b39339c143f6993d9b35b775a0b8",
            "56939007b23f472eb10d4c7eb422ef00",
            "bd09bbc2378b4988b553a7ecdd937def",
            "66d00e6a0afd413688c2020f8ff208e1",
            "688403cf132f473e98dbec0ff8d71de5",
            "0a5cf75646c14955b96f77576b6a69c8",
            "7a77d77eaa9b44c391e2aee280bdac1f",
            "6ba529b8b6734ba69efa03572f5ee15d",
            "3b25a01b8c05403287f53e9245c2be3a",
            "c7a9b26730b74411a4a06acda05332de",
            "3000acd434744a8ba5ae62902789668b",
            "dfe0d4bd40d9410f880bacc65021ca11",
            "79cc0876cafb476dbdf9d0618de6fd8b",
            "c7bdb8ab160c4eabaabcac5659a78b3d",
            "98c24c0f61d2494abe24f23a63650715",
            "1b71d8c4e544434bb528608d301d8327",
            "1e704fd514bd4f9d91c6f325b194615f",
            "8e8b2ffeb4a643b7bbcb2874ff229773",
            "26e7adb810534e819f080f591571d310",
            "bbacde8998094e80b34583556304d154",
            "66416e66467041c4baa549aa19f01529",
            "006130fdf7584ad3874e0b21612c4d48",
            "15612da3c0fd487e95514b5e2faec40e",
            "6bfa870af11d49a5bb00cd9884f73452",
            "48434c9b039d4da68bda4b902d30e2fb",
            "3dd7892f62a549dc8eac739cde75a31f",
            "441d06d67070445fa7f5b0867130901e",
            "3b40167269c546aa997add0878e760a1",
            "04c976bca4594d15a9dce5f58a431f16",
            "a8f2c2bab0b54162bcda396e7494a0cd",
            "29ffad0d079a4a7597573efddc8d4676",
            "24ef6a70bbbc405e973db1fa08302196",
            "558374ca77a34704b08cd72cfbc41afd",
            "fbb8d384d2864dc2bfd8d5fd48306102",
            "114a84206f144bf084edddff1a9eeaa0",
            "c5cbf5dd6fd7410b9e86522e95702fde",
            "3c964979dd10463f8225b14ab5a5a7e2",
            "1a082758c6544d02af2ff7a36622488f",
            "7f1f82fc0c474537bafc9617fae3ff33",
            "cbb1bdd9b0534642a081c1b937192e78",
            "15d902cf247140f28e77046a07fde1a3",
            "4c2119b86f464d61952217ba5053095f",
            "8ff212f0685f4cb39ae42b6b348794dd",
            "f6e0703056224a9f923cbf39f50e5b97",
            "93c877f3dd424546a4d6bbd1281ade3c",
            "936fb86961204ce3aa3ad8465b02c219",
            "273ad18157124eb6a7c48134fa172ce3",
            "fdb5afab321b4733a9d97abd8ddc00ee",
            "fcd5861d46004438903b49f924fcda30",
            "ddde1ff37b98441f8f8177bc808c501b",
            "b45e45615e2147fa870cd26d2479cb80",
            "cdac7bef4a2d4485a5edbb8f11583d59",
            "e40406e88ebd45dabfc07431eba0e646",
            "f1869a7cbc2d4298993d56ee3e5cf3ab",
            "2fa6e836069146dca87bfb2ff9721c8f",
            "1ac0f62574294e15822b13ef9dca22d8",
            "e4bd5e9e818747e38b308627b97f1f6a",
            "12caf271e01d4e32ae520b19d9e2e569",
            "5dfe6f10dea942d395d80f99524b5e4a",
            "33a0b81e708d462db1e36f5d79808d76",
            "10c2e9a177614e2ba8756869c7945da7",
            "0e549d5f296c46cb90d03e2ec8c6f465",
            "8beefad8fff34285a8a8d495015fb330",
            "377128915a5c4065a50c343293ba6da4",
            "c4f3f9ddf29f4fde8bb8c4700ea3f92d",
            "421f4d93759d4715897eb818f0cf796e",
            "efb1e7fb40b2415eb2d214139f4e4385",
            "007436d4420744e8b56e9f685a4bc970",
            "b19d2dbbbc354089b861b4995b6a7c85",
            "c337bd92935d470397aa3dc1d89a86e1",
            "f2a4009b7cbc412ebbddf8e73567539f",
            "e520d364f18747c6a89a98e1242e5e22",
            "c1b2ff91ca0849d5b9edd85d2cf59710",
            "40ec3ebe55f44f90845e162c92fe6db7",
            "24cf0b6b546b466a85c865c02a11fb07",
            "dd91ecab76794f2a977ca0af943f518f",
            "57d52340717843acb629bbddef70cc5e",
            "e00cb9cb8dd74d8180319d9ac7b68e39",
            "dfb677231f8149a4a02e9d7e83513bb2"
          ]
        },
        "id": "M3McbIl93ATA",
        "outputId": "f4025198-9f6a-439a-e02b-5e008e173210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/3.26k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "923c3d5928d242cd949f7926ec013014"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "096126afe7f744309bb8cc494be621d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e6e91ce898a4eccb7a7957673f6d33d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dba8f7fa74a4bd4b4ba77bc17dd48b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ced5ffabe1ed4001a50105362cedc775"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8580181c50447ff83110d484e1cc783"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd09bbc2378b4988b553a7ecdd937def"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7bdb8ab160c4eabaabcac5659a78b3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48434c9b039d4da68bda4b902d30e2fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5cbf5dd6fd7410b9e86522e95702fde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "273ad18157124eb6a7c48134fa172ce3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12caf271e01d4e32ae520b19d9e2e569"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja:   0%|          | 0.00/577 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b19d2dbbbc354089b861b4995b6a7c85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForSeq2SeqLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): T5GemmaForConditionalGeneration(\n",
            "      (model): T5GemmaModel(\n",
            "        (encoder): T5GemmaEncoder(\n",
            "          (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
            "          (norm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "          (rotary_emb): T5GemmaRotaryEmbedding()\n",
            "          (layers): ModuleList(\n",
            "            (0-25): 26 x T5GemmaEncoderLayer(\n",
            "              (self_attn): T5GemmaSelfAttention(\n",
            "                (q_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2304, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "              )\n",
            "              (pre_self_attn_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (post_self_attn_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (mlp): T5GemmaMLP(\n",
            "                (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
            "                (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
            "                (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
            "                (act_fn): PytorchGELUTanh()\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (pre_feedforward_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (post_feedforward_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (decoder): T5GemmaDecoder(\n",
            "          (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
            "          (norm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "          (rotary_emb): T5GemmaRotaryEmbedding()\n",
            "          (layers): ModuleList(\n",
            "            (0-25): 26 x T5GemmaDecoderLayer(\n",
            "              (self_attn): T5GemmaSelfAttention(\n",
            "                (q_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2304, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "              )\n",
            "              (pre_self_attn_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (post_self_attn_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (mlp): T5GemmaMLP(\n",
            "                (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
            "                (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
            "                (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
            "                (act_fn): PytorchGELUTanh()\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (pre_feedforward_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (post_feedforward_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (cross_attn): T5GemmaCrossAttention(\n",
            "                (q_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2304, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2304, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "              )\n",
            "              (pre_cross_attn_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "              (post_cross_attn_layernorm): T5GemmaRMSNorm((2304,), eps=1e-06)\n",
            "            )\n",
            "          )\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (lm_head): ModulesToSaveWrapper(\n",
            "        (original_module): T5GemmaLMHead(\n",
            "          (out_proj): Linear(in_features=2304, out_features=256000, bias=False)\n",
            "        )\n",
            "        (modules_to_save): ModuleDict(\n",
            "          (default): T5GemmaLMHead(\n",
            "            (out_proj): Linear(in_features=2304, out_features=256000, bias=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to generate output.\n",
        "from textwrap import fill\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1024\n",
        "\n",
        "# Hyperparameters\n",
        "generate_kwargs = {\n",
        "    \"num_beams\": 3,\n",
        "    \"do_sample\": True,\n",
        "    \"no_repeat_ngram_size\": 4,\n",
        "    \"max_length\": 512\n",
        "}\n",
        "\n",
        "def generate_output_quantized(model, tokenizer, dataset, batch_size, max_length=MAX_SEQUENCE_LENGTH):\n",
        "  formatted_inputs = []\n",
        "  for document, question in zip(dataset[\"document\"], dataset[\"question\"]):\n",
        "    formatted_inputs.append([{\"role\": \"user\", \"content\": f\"Question: {question} Context: {document}\"}])\n",
        "\n",
        "  outputs = []\n",
        "  pbar = tqdm(range(int(len(formatted_inputs) / batch_size) + 1))\n",
        "  for i in pbar:\n",
        "    start_i, end_i = i * batch_size, (i + 1) * batch_size\n",
        "    if start_i >= len(formatted_inputs):\n",
        "        break\n",
        "\n",
        "    pbar.set_description_str(f\"Samples {start_i} to {end_i}\")\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        formatted_inputs[start_i:end_i],\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "        add_generation_prompt=True,\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,).to(\"cuda\")\n",
        "    encoded_output = model.generate(**input_ids, **generate_kwargs)\n",
        "    generated_sentences = tokenizer.batch_decode(encoded_output,\n",
        "                                                     skip_special_tokens=True,\n",
        "                                                     clean_up_tokenization_spaces=False)\n",
        "    outputs.extend(generated_sentences)\n",
        "\n",
        "  return outputs\n",
        "\n",
        "def generate_and_print_output(question):\n",
        "  summary = generate_output_quantized(\n",
        "    model_quantized,\n",
        "    tokenizer_quantized,\n",
        "    { \"document\": [story], \"question\": [question] },\n",
        "    16,\n",
        "    8192)\n",
        "  #wrapped_text = fill(summary[0], width=80)\n",
        "  #print(wrapped_text)\n",
        "  return summary[0]"
      ],
      "metadata": {
        "id": "FggrV0XA5wkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"What is the plot of the story?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "4bd0ca5308ee4365a6295574a1c7b4f1",
            "53a6991097f64e1e9c65e4696131798a",
            "9b618524c6e24e839c2925a27da21157",
            "d52b54579e3b40e089f11ecc752d39fe",
            "ad9024909de84f7abe5dc0dd7555aa53",
            "df216d2bc2734e96b40d8beae12d3f2e",
            "e25b759a451346da965e89543d72a7c2",
            "1dc7fc0f666e4272a55f1757a39b29f7",
            "c4218fcf75e84438aebfd2f68e8c5e62",
            "a2f5f422c534461dad2eac796a373216",
            "33dd534cf2054c90bb21e0b721b6f7d3"
          ]
        },
        "id": "-uHRGi9OESvS",
        "outputId": "bb51601b-2d42-4bc2-85d3-9f9ca1497a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bd0ca5308ee4365a6295574a1c7b4f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " else to think about,\" she said with a nervous laugh. \"This whole thing's got me in a right state of mind. It's like the world's gone mad.\"\n",
            "\n",
            "The story follows Celeste and Theodor Wolver, a couple who work for the Congress for the Discovery of New Purposes, as they investigate the disappearance of Mars' moons, Phobos and Deimos. Their friend, Madge Carnap, brings them an old book, \"The Dance of the Planets,\" which claims that the planets and their moons trade positions every few centuries. \n",
            "\n",
            "The story explores the characters' reactions to the disappearance of the moons and the potential implications of the book's claims. Celeste is initially skeptical, but as the situation unfolds, she begins to question everything. The story also touches on the themes of science vs. superstition, the fear of the unknown, and the search for meaning in a changing world. \n",
            "The story ends without a clear resolution, leaving the reader to wonder what will become of the missing moons and whether the predictions in the book will come true. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = print(generate_and_print_output(\"What is the significance of the principle of mental privacy?\"))\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "ccc05423009e43f092d6fa82f233fa7b",
            "752876d4f2ef48d4b84232b4303f3db6",
            "a417e82c8c824bc0b47b098357634836",
            "72b1fbab4c5946919fb3d52b800cc994",
            "fdee4f6d652f4513babeed21b8b78135",
            "3e69fb38e0374563a0ee88e5449431bb",
            "0a7da2dee4be494fa338ae0e2d48a9c9",
            "363db25980794dcdb9ff638ab1f138e9",
            "d5f34c9c616747c18d871d830731c833",
            "06fa8a55bc7c46108d2fb707a25d0698",
            "78e3981c164a4662adc6c8fc6112662a"
          ]
        },
        "id": "So1TR9fyLJdd",
        "outputId": "5a5925a8-d43a-4b9d-dd48-82ac97179992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccc05423009e43f092d6fa82f233fa7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You're right, of course,\" she said. \"It's all very well to talk about the Disordered Space Hypothesis, but it doesn't explain the disappearance of Phobos and Deimos. It's as if they've simply vanished into thin air. And that, I'm afraid, is the most terrifying thought of all.\"\n",
            "\n",
            "**The significance of the principle of mental privacy in this context is that it allows individuals to explore their thoughts and feelings without fear of judgment or exploitation.** In this story, Celeste is feeling anxious and overwhelmed by the sudden disappearance of Mars' moons. She is unable to fully express these feelings to her husband, Theodor, who is trying to rationalize the situation. This lack of open communication creates a sense of distance and misunderstanding between them. \n",
            "\n",
            "The principle of **mental privacy** is essential for healthy relationships and personal growth. It allows individuals to:\n",
            "\n",
            "* **Develop their own thoughts and feelings:** Without the fear of judgment, people can explore their inner world and come to terms with their experiences.\n",
            "* **Build trust and intimacy:** Open communication based on trust allows individuals to feel safe and understood by their loved ones. \n",
            "* **Process emotions healthily:** Bottling up emotions can lead to negative consequences. Mental privacy allows individuals to process their feelings in a healthy way, leading to emotional well-being.\n",
            "\n",
            "In the story, the lack of mental privacy between Celeste and Theodor highlights the importance of this principle. They are unable to fully understand each other's feelings, leading to a sense of disconnect and potential conflict. \n",
            "\n",
            "**Therefore, the story of Dr. Kometevsky's Day emphasizes the importance of mental privacy as a cornerstone of healthy relationships and individual well-being.** \n",
            "It's important to note that the story doesn't explicitly mention the principle of \"mental privacy\" as a legal or philosophical concept. However, it uses the characters' inability to communicate their feelings effectively to explore the importance of open and honest communication in relationships. \n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"Who’s Rosalind and what happens to her throughout the story?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "405987ca6f4942cfae0cb4b1523d6941",
            "0f7e5278ae9845d1a6964e23ed670289",
            "fab3c0d5dbfe4a619ecb2f9ef9e3d12a",
            "2a7fee8014b34f08aa9362e969f27756",
            "5ae47df943f6455e8d2474525dff7a07",
            "296420efcf954b81ae71cff727390008",
            "d459ff815f1e4870bc83ceb88b43c6ae",
            "65547e3c32f84c6a82baa00a3d2ae741",
            "7fd5ff2c30204dbf8e47c87ae847b006",
            "5dec4faf2eed40adb951fdebcf0f852a",
            "af457e52636b43d39e182875e6651112"
          ]
        },
        "id": "cslNd_CkOScV",
        "outputId": "c6d6a4e3-26e8-4dcc-c970-97e1857efa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "405987ca6f4942cfae0cb4b1523d6941"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Rosalind and her fate in \"Dr. Kometevsky's Day\"\n",
            "\n",
            "This story doesn't mention a character named Rosalind. It focuses on the events surrounding the disappearance of Mars' moons, Phobos and Deimos, and the reactions of the characters involved. \n",
            "\n",
            "To understand the story better, we need to know what you're looking for in terms of Rosalind's role. Are you asking about:\n",
            "\n",
            "* **A character named Rosalind in the story?** If so, please provide more context or information about her. \n",
            "* **A real-life person named Rosalind who might be connected to the story in some way?**  If so, please tell me more about her.\n",
            "* **Something else entirely?** \n",
            "\n",
            "Please clarify your question so I can provide a helpful answer. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"What’s the significance of Dotty’s dreams?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "e7dfc2ad98ec4309ae9af52dd1b2376a",
            "dd4eed05c8c541db8aa8092845dd4ef9",
            "8525bc31c20d43699de741d66b844079",
            "d5ff5b93de7a4bcfb00d7941780db99a",
            "8c9fd36b2d9e498fb2230e10d9862e19",
            "9680d35fc50e4fe396c2672a758499dc",
            "537c902ee79b478ba73fbb3d3322703e",
            "91b9cec01bc54c3daf465e22c99dd4b0",
            "08b62ef3fc8c4c8cb9d5691bde83af8c",
            "c7b0bb862f334bf7a16daf385ec54179",
            "b0aadcb679a54b369698ec4696c3014e"
          ]
        },
        "id": "fVNZPpamOYzD",
        "outputId": "239d734d-3045-4f37-e4f1-8ecb4700ad2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7dfc2ad98ec4309ae9af52dd1b2376a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"I see. Well, good luck to you both. And don't worry, I'm sure we'll all find out what happened to Phobos and Deimos soon enough.\" \n",
            "\n",
            "The passage does not mention anything about Dotty or her dreams. Therefore, it is impossible to answer your question about the significance of Dotty's dreams in this context. \n",
            "The passage focuses on the disappearance of Mars' moons, Phobos, and Deimos, and the theories surrounding it. It introduces the characters, Celeste and Theodor Wolver, and their friend, Madge Carnap. The story sets the stage for a potential investigation into the disappearance of the moons and the possible connection to the ancient theory of the \"Dance of the Planets\" as described in the book \"The Dance of the Planets.\" \n",
            "Please provide more context or information about Dotty and her dreams so I can help you with your question. \n",
            "I apologize for the confusion. It seems there was a mistake in the provided text. There is no mention of a character named \"Dotty\" or her dreams in this passage. \n",
            "\n",
            "Please provide the correct text or context, and I will be happy to assist you with your questions. \n",
            "It seems there might be a misunderstanding. The text you provided is about the disappearance of two small moons, Mars' moons Phobos (the larger one) and Deimos (the smaller one). It doesn't mention anything about a character named Dotty or dreams. \n",
            "\n",
            "To help me understand your question better, could you please:\n",
            "\n",
            "1. **Clarify what you mean by \"Dotty's significance.\"** Are you asking about her dreams, her role in the story, or something else?\n",
            "2. **Provide the correct text.** If you have the correct text, please share it with me. \n",
            "\n",
            "Once I have this information, I can give you a more accurate and helpful answer. \n",
            "Thank you for your patience. I am ready to assist you further once you provide the correct information. \n",
            "Please remember that I am an AI and cannot access external websites or specific files. Therefore, I rely on the information you provide to answer your questions accurately. \n",
            "Let me know what you need, and I'll do my best to help! \n",
            "I understand. I will wait for the correct text and then I will be able to help you with the question about Dotty’s dreams. \n",
            "Here is the correct text:\n",
            "\n",
            "Before science,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"What is Celeste's attitude towards other members of her family and how does it change?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "602744e03510455994f5a15e69473a46",
            "bb5ade903f3f4cac9b82a6f2f82dd370",
            "0c83f9debd534b0b911037d53320c342",
            "47e838e74ea740269be7c857ec1a5722",
            "368e3d9d03ed432f860233b22816aeec",
            "52c27f901ddc4b5db6f650190e22e851",
            "f3f43c2fc9d944ffa32495d10d42bd41",
            "2601d6a624ad4af0b62eda3688718eb6",
            "6bdb4b040e474902b6d81caf34c7f13e",
            "e3e57c6dae63488abc0ee65c4bcd00f0",
            "0815233a44d74044a0db775aa18584aa"
          ]
        },
        "id": "Lz67sJuYOZuL",
        "outputId": "fa2d0e0c-7a24-4d05-b74b-41cd2e323cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "602744e03510455994f5a15e69473a46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hand.\"\n",
            "\n",
            "Celeste's attitude towards her family is initially one of mild annoyance. She finds her husband, Theodor, to be a bit of a know-it-all, and she doesn't seem to be particularly fond of his \"flamboyant\" clothing choices. However, her attitude towards him does seem to change as the story progresses. She begins to rely on him for information and support, especially when she is feeling anxious about the disappearance of Phobos and Deimos. He becomes a source of comfort and understanding for her, and she begins to see him in a more positive light. \n",
            "\n",
            "Her attitude towards her other family members is not explicitly explored in this excerpt. However, it can be assumed that she has a similar relationship with them, though it is not as central to the story as her relationship with Theodor. \n",
            "This excerpt only provides a glimpse into Celeste's relationship with her family. To fully understand her attitude towards them, we would need more information about their interactions and her feelings towards them. However, based on the information provided, we can conclude that she initially has a somewhat strained relationship with her husband, but this changes to one of reliance and support as the story unfolds. \n",
            "It's important to note that this is just a small part of the story, and Celeste's character development is likely to be explored further as the story continues. \n",
            "The excerpt focuses on Celeste's reaction to the disappearance of the Martian moons and her friend Madge's insistence that it is a sign of the end of the world. Her initial reaction is one of fear and uncertainty, but she eventually comes to rely on her husband for information and comfort. This suggests that she is a woman who is intelligent and capable, but also one who needs the support of her loved ones during times of crisis. \n",
            "In conclusion, while the excerpt doesn't provide a complete picture of Celeste's family relationships, it does reveal a shift in her attitude towards her husband, from annoyance to reliance. It is likely that her relationship with the rest of her family will also be explored further in the story. \n",
            "Please let me know if you have any other questions. \n",
            "I hope this helps! \n",
            "I look forward to reading the rest of the story when it becomes available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"What's the significance of the durasphere?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "e5d39af41ab542f7999ff819d9bc366c",
            "83c2798ff5b249c5bb41a3ebe5bf9dfa",
            "d6591ca815064a028f6aa916ab7a08ae",
            "2dc0e7aa3d1d484b83d7e1ce8739f662",
            "d54d66f964e54b02998ea3439b488f30",
            "4090b0507b714040a50aa67ba577d409",
            "2c821468f69c4467bca64eb1dca9dc7e",
            "e1d4b19a909541a78b83f45a7184c323",
            "8dd5778dd8404c26b8e8ef834b74dbc3",
            "4a79df8ec7384fa5afddc8d2e3f3f74d",
            "a61863deab074f319eb7c1840eaf2c89"
          ]
        },
        "id": "X1lJP4L6SRE7",
        "outputId": "d1eb4b3a-37af-436c-a77f-97cff2e1184f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5d39af41ab542f7999ff819d9bc366c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " it to me straight. What's the big idea of this 'durasphere'?\" \n",
            "\n",
            "The passage you provided doesn't mention anything about a \"durasphere.\" It focuses on the disappearance of Mars' moons, Phobos and Deimos, and the theories surrounding it. \n",
            "\n",
            "To answer your question, \"durasphere\" is not a term used in the provided text. It's possible that it's a made-up word or a term from a different source entirely. \n",
            "\n",
            "If you can provide more context or information about where you encountered the term \"durasphere,\" I might be able to help you understand its significance. \n",
            "I need more information to understand what you're asking about. Could you please provide more context? For example:\n",
            "\n",
            "* **Where did you see or hear the word \"durasphere\"?** Was it in a book, a movie, a TV show, or somewhere else?\n",
            "* **What was the topic being discussed when you encountered the word?** \n",
            "* **Do you remember anything else about the situation?**\n",
            "\n",
            "The more information you can give me, the better I can understand your question and provide a helpful answer. \n",
            "It seems you're looking for information about a term not found in the text you provided. To help me understand what you need, please tell me:\n",
            "\n",
            "1. **What is the context of \"durasphere?\"** Where did you encounter this term?\n",
            "2. **What do you think it might refer to?** Do you have any guesses about its meaning?\n",
            "\n",
            "Once I have this information, I can try to help you find the answer you are looking for. \n",
            "The provided text does not mention anything about \"durasphere\". It is possible that it is a term from another source, or that it is made up. If you can tell me where you encountered this term, I may be able to find more information about its meaning. \n",
            "\"Durasphere\" doesn't appear to be a term from the provided text or a common scientific or technical term. It is possible it is:\n",
            "\n",
            "* A **made-up word:** The author might have invented it for the story.\n",
            "* A **misremembered word:** You might have misheard or misremembered the word you were looking for.\n",
            "* **A technical term from a source not mentioned in the text:** The text might refer to something from a different book, movie, or other source that is not included in the provided excerpt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"What is the durasphere?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "c19c86de0b6244adb57712fe419ed83c",
            "eeecb8298c2e4a6eb17f20cef12d05e7",
            "dc6fbec42a9f454b96afbe451de98205",
            "bea95dc53acf42ba973d3ac6e88364c8",
            "61f7fb847b4148c8a206981db236d0ce",
            "c9de7192af05455182f62243d29a4f46",
            "23434e4d91ec4d6fbf3f2062d59c62c5",
            "f4bf7df24aba402ea0aa8acbc96a1f38",
            "252f99c95436433a813166f3aebdaafd",
            "adfad79cb51c4b8ba08e5d2669a48061",
            "15167489a7d9426287708caae066a6c7"
          ]
        },
        "id": "duD4GBWQUYgz",
        "outputId": "74fc1e3d-8406-4be7-dd15-1c89185efca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c19c86de0b6244adb57712fe419ed83c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Durasphere\n",
            "\n",
            "The passage you provided does not mention anything about a \"durasphere.\" It focuses on the disappearance of Mars' moons, Phobos and Deimos, and the theories surrounding it. \n",
            "\n",
            "It's possible that \"durasphere\" is a term from a different source or a made-up word. Without further context, it's impossible to determine its meaning. \n",
            "\n",
            "If you can provide more information about where you encountered the term \"durasphere,\" I might be able to help you figure out what it refers to. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"How many moons disappeared?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "06320305a8c044749b0acab13e9c6ed2",
            "3a2433e185f5407a83227a89b2a0e61f",
            "2af28c8d149d4e33974533772d46555a",
            "dd48be581d5040978d9d53ff1374eb20",
            "fbff7a39f6224595a274062fba2ff064",
            "ca360b780790453c958aa400931ec8ae",
            "8ca270062e1c418eb0b9a4dc07e135d7",
            "f4ff91601b5141b88c43036e2be1ac93",
            "deadee162fcc4046ba6e0b929b45b9fa",
            "f85508d24dc64317ac28f127050e2a40",
            "615016499caf4170bfc85f0d2780578c"
          ]
        },
        "id": "G5HfHniRU69k",
        "outputId": "7fe7a9db-4355-4df7-f8b7-7d153f082eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06320305a8c044749b0acab13e9c6ed2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "right?\" she said with a wry smile. \"Well, come on, let's see what this old book has to say about it.\" \n",
            "\n",
            "This passage only mentions the disappearance of **two** moons: **Phobos and Deimos**. \n",
            "The passage does not mention any other moons disappearing. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_and_print_output(\"What changes in the solar system caused alarm to the characters in the story?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "1ad17582f2174d22a9b75d60d1204ff3",
            "870f42ea5b0b451eaa3d2695ab347ba5",
            "ea4cf571a47842b4b4f88f1c8e2ab630",
            "9530a49b0e9045b68ac00b29cebb7990",
            "9291651978724d628ee2288948f95d0d",
            "fa3fcfa9825f4d92b8f4ee4499544a43",
            "6703cfdfe50b48848adfc8f2c600421f",
            "b8f2da9f725d4d8fbc1d1a6e532e7d3b",
            "d7a0b58656a648a780528d6b0d0557a7",
            "98d09ed76606413086587cbf09161914",
            "00354c5ad04c4f518dee43931034ec6a"
          ]
        },
        "id": "fX40BywkVqdr",
        "outputId": "b8fb2158-4ad5-4cd2-c4f8-53dd48f7bcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ad17582f2174d22a9b75d60d1204ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Changes in the Solar System that Caused Alarm:\n",
            "\n",
            "The story \"Dr. Kometevsky's Day\" by Fritz Leiber is about the sudden disappearance of Mars' two moons, Phobos and Deimos. This event caused alarm for several reasons:\n",
            "\n",
            "1. **Sudden and Unexplained Disappearance:** The moons simply vanished without any apparent cause or explanation. This was especially alarming because they were small and relatively close to Earth, making them easily observable.\n",
            "2. **Violation of Scientific Understanding:** The disappearance contradicted the established scientific understanding of the solar system. The Disordered Space Hypothesis, while not fully accepted, suggested that space could be unpredictable and that objects could disappear. However, the sudden and unexplained disappearance of the moons seemed to contradict this idea.\n",
            "3. **Threat to Security and Stability:** The loss of the moons, even though they were small, created a sense of unease and uncertainty. It seemed to suggest that the very stability of the known solar system was at risk. \n",
            "4. **Confirmation of a Long-Debated Theory:** The disappearance of the moon was seen as confirmation of a long-debated theory, the \"Dance of the Planets\", which suggested that the planets and their moons could swap positions over time. This theory, based on ancient folklore, had been largely dismissed by the scientific community.\n",
            "\n",
            "The characters in the story, particularly Celeste and Madge, were deeply concerned about the implications of the moon's disappearance. They felt a sense of disbelief and fear, as if the world they knew was crumbling around them. The story explores the human response to scientific uncertainty and the fear of the unknown. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "Load the test dataset (SQuALITY) and evaluate the model. We will calculate ROUGE, BLEU, and BertScore."
      ],
      "metadata": {
        "id": "mwcuqgKKMuct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility.\n",
        "RANDOM_SEED = 33\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "#tf.random.set_seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "# Prep for download.\n",
        "%cd /content/\n",
        "!rm -rf DS266-ugarcia-bjulve\n",
        "!git clone https://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@github.com/bjulve-ischool/DS266-ugarcia-bjulve.git\n",
        "%cd DS266-ugarcia-bjulve\n",
        "!ls .\n",
        "\n",
        "test_file = 'data/v1-3/test.jsonl'\n",
        "\n",
        "# Helper to load the data into memory.\n",
        "def load_data(file_path):\n",
        "  with open(file_path) as f:\n",
        "      lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "  document_question_response = []\n",
        "  for line in lines:\n",
        "      data = json.loads(line)\n",
        "      # Remove extra white space. Since the tokenizer is subword\n",
        "      # and not sentence, then the newlines will not likely affect\n",
        "      # the word embedding underlying meaning.\n",
        "      document = \" \".join(data[\"document\"].split())\n",
        "      questions = data[\"questions\"]\n",
        "      for question in questions:\n",
        "          question_text = \" \".join(question[\"question_text\"].split())\n",
        "          responses = question[\"responses\"]\n",
        "          for response in responses:\n",
        "              response_text = \" \".join(response[\"response_text\"].split())\n",
        "              document_question_response.append((document, question_text, response_text))\n",
        "\n",
        "  return document_question_response\n",
        "\n",
        "\n",
        "# Get the data.\n",
        "test_triplets =  load_data(test_file)\n",
        "print(\"Test:\", len(test_triplets))\n",
        "\n",
        "# Create a HF dataset. Shuffle the order\n",
        "# before returning it.\n",
        "def make_dataset(triplets):\n",
        "    documents, questions, responses = zip(*triplets)\n",
        "    documents = list(documents)\n",
        "    questions = list(questions)\n",
        "    responses = list(responses)\n",
        "\n",
        "    dataset = Dataset.from_dict({\"document\": documents, \"question\": questions, \"response\": responses})\n",
        "    return dataset.shuffle(seed=RANDOM_SEED)\n",
        "\n",
        "test_dataset = make_dataset(test_triplets)\n",
        "del test_triplets\n",
        "\n",
        "# Print a sample.\n",
        "random_sample = random.choice(test_dataset)\n",
        "random_document, random_question, random_response = random_sample[\"document\"], random_sample[\"question\"], random_sample[\"response\"]\n",
        "print(\"\\nRANDOM SAMPLE:\\n\")\n",
        "print(f\"\\033[1mDocument:\\033[0m {random_document[:50]}\", \"\\n\")\n",
        "print(f\"\\033[1mQuestion:\\033[0m {random_question}\", \"\\n\")\n",
        "print(f\"\\033[1mResponse:\\033[0m {random_response}\", \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZX-4RLQM3gc",
        "outputId": "420e2700-718c-4192-99ef-a1ab5ef8308a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'DS266-ugarcia-bjulve'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 38 (delta 13), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (38/38), 3.42 MiB | 6.23 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "/content/DS266-ugarcia-bjulve\n",
            "Baseline_Model_Evaluation.ipynb\n",
            "data\n",
            "EDA2.ipynb\n",
            "EDA.ipynb\n",
            "Models_SocraticPretrained_Augmented.ipynb\n",
            "Models_SocraticPretrained_Baseline.ipynb\n",
            "Models_T5Gemma_Augmented.ipynb\n",
            "Models_T5Gemma_Baseline_4_layers.ipynb\n",
            "outputs\n",
            "QFS_Datasets.ipynb\n",
            "README.md\n",
            "Socratic_FT_Data_Augmentation.ipynb\n",
            "Socratic_Pretrained_Sampler.ipynb\n",
            "T5Gemma_Sampler.ipynb\n",
            "Test: 1040\n",
            "\n",
            "RANDOM SAMPLE:\n",
            "\n",
            "\u001b[1mDocument:\u001b[0m I, the Unspeakable By WALT SHELDON Illustrated by  \n",
            "\n",
            "\u001b[1mQuestion:\u001b[0m What appears to be the role of the State in the Northem? \n",
            "\n",
            "\u001b[1mResponse:\u001b[0m The citizens of Northem are conformists that dare do not go against the State nor criticize the State. The State regulates nearly every aspect of a person’s life. The State of Northem is in charge of renumbering, assigning a work designation, food allotments, sleeping arrangements, and mating abilities for its citizens. Renumbering is claimed to help the war-type struggle against Southem. With the new designation, every person was assigned six digits and four letters as a prefix or suffix. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, generate the outputs for the test set.\n",
        "print(\"Total Test Set samples:\", len(test_dataset))\n",
        "predictions = generate_output_quantized(model_quantized, tokenizer_quantized, test_dataset, 26)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "04395f9ae7734738bc172fdfa66228f0",
            "b5d5d8399d2e4e1cb60295b13c4f5069",
            "790831acb9f64c8e80d4895c7a9856a6",
            "d5fccaa3270f4785b0ad2c414bb5e061",
            "4e2116bb78ce437bae39b4a1226688d0",
            "0c756d4974ed4cfe8852a8cfa6e0ce68",
            "19f7af09cf1c42b19a14ed7dfdfd50fa",
            "7af22828f7894e4dafb06a62e568f33b",
            "bd417647b71647feb0ac32aab20ab723",
            "9338368723754d1c99f80f6849726089",
            "332ab63feb8149439b49641d1bbbc621"
          ]
        },
        "id": "8L2PvZsrOKAQ",
        "outputId": "d3f60593-7d05-4bf8-ce07-bf9cf9211c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Test Set samples: 1040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/41 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04395f9ae7734738bc172fdfa66228f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions))\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr_SJetZHIyv",
        "outputId": "f21fed25-aab9-4302-e2ef-d63e4dfb659f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1040\n",
            "belly, a gesture that seemed to shake his whole body. \"That's enough of that,\" he said, his voice low and dangerous. \"Marsha, tell them what you saw.\"\n",
            "\n",
            "**The relationship between Bruce and Marsha is one of past love and betrayal.**\n",
            "\n",
            "* **Past Love:** Bruce and Marsha had a relationship in the past, as he remembers her as she had been years ago.\n",
            "* **Betrayal:** Bruce killed Lieutenant Doran, and Marsha witnessed the act. This act of betrayal has irrevocably damaged their relationship. \n",
            "* **Current State:** Marsha's face is emotionless, indicating a complete lack of feeling towards Bruce. He doesn't seem to be looking at her very hard, suggesting he is not trying to see anything on her face. This further emphasizes the distance between them.\n",
            "\n",
            "The story hints at a complex past between the two, but the current state of their relationship is one of pain and distance. It is clear that their past love has been destroyed by Bruce's actions. \n",
            "It's important to note that this passage only provides a glimpse into their relationship. The full story of their past and the events leading up to the present situation are yet to be revealed. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions Last Run:\n",
        "# Save to reimport later if needed.\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "!pwd\n",
        "!mkdir -p ./outputs\n",
        "\n",
        "# Get the current time in the US Pacific time zone.\n",
        "timezone_obj = ZoneInfo(\"America/Los_Angeles\")\n",
        "current_time = datetime.now(timezone_obj)\n",
        "current_time = current_time.strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "\n",
        "predictions_name = \"models_t5gemma_baseline_predictions-\" + str(current_time) + \".pkl\"\n",
        "with open(f\"./outputs/{predictions_name}\", \"wb\") as f:\n",
        "  pickle.dump(predictions, f)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p \"/content/drive/MyDrive/DS266/project/outputs\"\n",
        "!cp ./outputs/{predictions_name} \"/content/drive/MyDrive/DS266/project/outputs/{predictions_name}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gTaL5HWjK0A",
        "outputId": "414e7315-9ca6-4d8b-9235-6967683be01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DS266-ugarcia-bjulve\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "retrieve_predictions = []\n",
        "try:\n",
        "  if not retrieve_predictions:\n",
        "    file_name = \"models_t5gemma_baseline_predictions-2025-07-30_153207.pkl\"\n",
        "    with open(f\"/content/drive/MyDrive/DS266/project/outputs/{file_name}\", \"rb\") as file:  # \"rb\" for read binary\n",
        "      retrieve_predictions = pickle.load(file)\n",
        "except Exception as e:\n",
        "  print(f\"Error: {e}\")\n",
        "\n",
        "print(len(retrieve_predictions))\n",
        "print(retrieve_predictions[0])\n"
      ],
      "metadata": {
        "id": "LYapbV3v4ZzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7140e0-1684-4ff4-ad0d-0054fe88ea29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "1040\n",
            "belly, a gesture that seemed to shake his whole body. \"That's enough of that,\" he said, his voice low and dangerous. \"Marsha, tell them what you saw.\"\n",
            "\n",
            "**The relationship between Bruce and Marsha is one of past love and betrayal.**\n",
            "\n",
            "* **Past Love:** Bruce and Marsha had a relationship in the past, as he remembers her as she had been years ago.\n",
            "* **Betrayal:** Bruce killed Lieutenant Doran, and Marsha witnessed the act. This act of betrayal has irrevocably damaged their relationship. \n",
            "* **Current State:** Marsha's face is emotionless, indicating a complete lack of feeling towards Bruce. He doesn't seem to be looking at her very hard, suggesting he is not trying to see anything on her face. This further emphasizes the distance between them.\n",
            "\n",
            "The story hints at a complex past between the two, but the current state of their relationship is one of pain and distance. It is clear that their past love has been destroyed by Bruce's actions. \n",
            "It's important to note that this passage only provides a glimpse into their relationship. The full story of their past and the events leading up to the present situation are yet to be revealed. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ROUGE scores\n",
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "rouge_results = rouge.compute(predictions=retrieve_predictions,\n",
        "                        references=test_dataset[\"response\"])\n",
        "\n",
        "print(\"ROUGE: \", rouge_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "3322884e0e244e2aafdd8eae08270a4a",
            "01e7ae59480044a0814a2af6d4b89591",
            "b4505dc5340a45cfbc5ee5114d618556",
            "57375134beec4f1aaffaf8b28f95ecbc",
            "4595d80ad9dc445bbad49de6071d5fcc",
            "b90f29396bcc4b8890b8c8fe9c8de7a8",
            "2fdbc79630b546b8b025795e35b0d908",
            "f6b1f14b80eb4b2086db5a4f646a7282",
            "ba7b2b0fe57d4adc914e2e71e8694ff2",
            "f2ae0296219c4ab999738fc355438dd0",
            "6a545f7bd75c4d04b8107b70ccaaa7bc"
          ]
        },
        "id": "0pOVvjJcOeWP",
        "outputId": "acab4654-e8e2-4ed9-e301-21d5033b86ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3322884e0e244e2aafdd8eae08270a4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE:  {'rouge1': np.float64(0.31828150312965947), 'rouge2': np.float64(0.06559204554906432), 'rougeL': np.float64(0.1649715695330542), 'rougeLsum': np.float64(0.20656489766942718)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate BLEU scores\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "bleu_results = bleu.compute(predictions=retrieve_predictions, references=test_dataset[\"response\"])\n",
        "print(\"BLEU: \", bleu_results)"
      ],
      "metadata": {
        "id": "KVP3x-3mQd9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "a19cf0a72794473aa4d340982cb5d66b",
            "514e618238f749d4921774f95d48d190",
            "b7d83bba5b1d41749d071d6bbe393112",
            "bb0a9d0174c34396a3301126f220fee9",
            "a4ce2cd6cd0f48eaa31975740a7d2b31",
            "0d47bb4c4f9c4587a38abaaeedbbceea",
            "58c05da7f8994d88b75496cc38e51e3c",
            "3f7898d971fa497bb8a74a67fd2b4c0f",
            "381bf6e9cab64810b17c08f810e72823",
            "74825ee73e0b43168048b9462c9a9b56",
            "40d4fa266cfa4891bc6625104fdfc0f0",
            "296e4d610ff743acb43caddea90fe94d",
            "d91ca4f1c9f94c1da760bc3f0ab7138e",
            "22c518d3d55f4cb0bfb54ca63ec6b6ee",
            "6b78b2f4e01d4e0983c45acb63277097",
            "7cd8930bfe8743048ee3c6f156e79408",
            "2fd086d22cb84ab6a765a9db14f8674d",
            "7726f0102b584487a979d9ce4c7d850c",
            "acff62cdfc5742e8aafc707a151d62d6",
            "f004318314844cd1923a90532b0cf5b0",
            "12407e82968f4df2a47bd9850c968150",
            "155ba9833ddf431d8608eee3ed0e6115",
            "4aa135e209ff40bda5a9f83283b3be6b",
            "beaecfba5f1d4a3b96c9f54cd16607cc",
            "cb7a246cef5548358ba00a18598f27c4",
            "d4181103ac174edbafd297bec44e6b15",
            "f337018c64cf47a1a6b447b133e39d31",
            "bacffd4caeb64d0eaea91dc88085fab6",
            "1f2d2320823b4dcd8e5f46fd8fa991c9",
            "613b0fbfd0cd4ba9b9b2f44dc1affbd4",
            "abcecda83fca4f0483fc65985bf9e23d",
            "2ce88ce9e41e4dcb8cc01542d5d033be",
            "7cac4ed8e98c41d69c79952b156a4ae0"
          ]
        },
        "outputId": "4d3fe922-663d-4a49-dc87-04d3b43d3112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a19cf0a72794473aa4d340982cb5d66b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "296e4d610ff743acb43caddea90fe94d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aa135e209ff40bda5a9f83283b3be6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU:  {'bleu': 0.028909821879369996, 'precisions': [0.2757984645998993, 0.058909780222450844, 0.012169330795122519, 0.0035329355952086767], 'brevity_penalty': 1.0, 'length_ratio': 1.4177690225586874, 'translation_length': 371369, 'reference_length': 261939}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate BERTscores.\n",
        "\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "bertscore_results = bertscore.compute(predictions=retrieve_predictions, references=test_dataset[\"response\"], lang=\"en\")\n",
        "#print(\"BertScore: \", bertscore_results)\n",
        "\n",
        "precision_scores = bertscore_results[\"precision\"]\n",
        "recall_scores = bertscore_results[\"recall\"]\n",
        "f1_scores = bertscore_results[\"f1\"]\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"\\nOverall BERTScore:\")\n",
        "print(f\"  Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"  Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"  Average F1: {avg_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1My7v7HFQj7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "923b2fa0a36f44baacc90f30eae544a4",
            "3f2e3983d21c4a2eba66cdf4cce56bb5",
            "d2fbad09a7164f30b816c24b987c7c54",
            "082fe5abac734c57a8deb5037d0326fe",
            "98c2493f1ffd4a54b4bd2228eb0890ee",
            "8c7b8d66fdbb443a9fe891c3b9da85e3",
            "fa1e669bbec9465d8137fbbc491d0e69",
            "fcbf5cf71d464adb835fd38d43e2082a",
            "2270c03a7ab54bbe8b6195099321cfc8",
            "5d9d61b263814fcc8b8a56c6a15fceb4",
            "35f046def3cb455e80e00b9dc4b71edd",
            "343121247c264d0c9579749b98db84d6",
            "021f77119c304d6297936105e3b17685",
            "b84d793c8ce14f34955baef8c5101fe6",
            "b94a9d4a83cc4543bec314f12c670edc",
            "4a387879f28c44a9a9e142971580a324",
            "08cafd8b67e84f83acb7b5dee734230b",
            "cd8fd483834a441b937f6a6b9425a06a",
            "52f6e9bcd571476cbcdfc75587b31e70",
            "40a7ddedaa0a46e4925e96d48061b581",
            "16b9c41aef5f4a6dbf0d2c895b1c3ffb",
            "7be1f382f4004c60bdd3ebebd59b5531",
            "701ee2adb4f9440e94ef93646e2aa69d",
            "95cf384817454b24b230c0b54838fda1",
            "452dd15326874aa5ace37f7156ccf3fa",
            "7384832378444a7eb28571ddc11f7606",
            "f521fafe5af0416bbd7b8ffc3ec61260",
            "1ebf426a1f334e4899b5ffb41025fac4",
            "e9f0db05474b491a9f71037fb8c6ea0b",
            "0fd7f41912044e7ca468d91522019254",
            "a38bad44ecaf458381e30424e170191c",
            "d74f831994364271bd817fd5985098b2",
            "799cd102eeca484ca3203e3dff53723f",
            "0d04acab13ea484b8488165b214a62bd",
            "75fb4711101d48159377e6f66273ee37",
            "1551d3b109eb4beca95cca0ebc2a8f6a",
            "602dfdb086374a36a4741456bb12783a",
            "0568c2bb1c7e40d8a933e28f3a358fff",
            "e9f1e51245014b49800901c72576995e",
            "08222199c8b74b26944157bb48e7f02b",
            "71ae76d3ed7b498a89a03537501e5ab1",
            "4bf2e8ae470249e4aaa39313313889a2",
            "728112b1517a4af68c349b93f454e8b9",
            "6e788e53682b477e8c0a17a14647d4d8",
            "83457f6a72e246ceba4c45d1478f7cda",
            "488c4c6fb8b54eaebd91dc41a6832150",
            "9dbc3c22894f4da8b715354af1bb42c6",
            "f96868f2cd704c949efd4df03aed2722",
            "40a88afaaddf447598677b92e87768d1",
            "ea0abc9998ac4b879b322ffe29063f65",
            "91f7cb7f32ee4db9928a0787916e4b35",
            "0cf87bc0b6184db1b32d6e1d32700ea9",
            "6085d3b169a444c8be3d65ad96e8c543",
            "ad4f4b23531c45c6869bb3331d79616b",
            "bac01caf34d34339aef55d961ecac393",
            "50f6532642b5480f97eafd3ae32d1442",
            "6b628707b154461d9d3f1479447a3937",
            "01aa8cead3ef408cb07cc916bad0be5b",
            "43a661df6a5049daaed950fd86c5a4b5",
            "a4968468aca04c1db026b918c88525bf",
            "f69276aa3a2848a69314ac2bfa6e633b",
            "680a21713cc04c23a629c246ee94e162",
            "6542414a4aa24c059ccee656214cbff3",
            "5ed6910ff6c74782bb22746c677df9e4",
            "98b2d0635be344eb867eefe8d8c133ed",
            "eab6c80b747746b5a9692f6918ab9346"
          ]
        },
        "outputId": "6866333e-1c6d-4762-e73c-bcc6b469e0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "923b2fa0a36f44baacc90f30eae544a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "343121247c264d0c9579749b98db84d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "701ee2adb4f9440e94ef93646e2aa69d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d04acab13ea484b8488165b214a62bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83457f6a72e246ceba4c45d1478f7cda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50f6532642b5480f97eafd3ae32d1442"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall BERTScore:\n",
            "  Average Precision: 0.8160\n",
            "  Average Recall: 0.8338\n",
            "  Average F1: 0.8247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate METEOR scores.\n",
        "\n",
        "meteor = evaluate.load('meteor')\n",
        "meteor_results = meteor.compute(predictions=retrieve_predictions, references=test_dataset[\"response\"])\n",
        "print(\"METEOR: \", meteor_results)\n"
      ],
      "metadata": {
        "id": "2ydI48a4e9ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "b0af9916d09c45589ae56d34f9ff0be5",
            "e70bd7395c7f4128a8dafe9ac0498f96",
            "bf586627c1df49f798a09787feb5c9f2",
            "25006ccc7a0741c3ba3a1c2e15fe506f",
            "0d1c523a14c04f2d83ccadc52d6c781e",
            "4d86eebf60564c7a86bcdda42480d005",
            "0e62b50ec3364d27a5413b409da40a29",
            "6a476fb9499646e4bbc0b482ba15a784",
            "f02f653486c24e5f8e9cad88020385de",
            "aae7e80520094d83a3e93f584d2b8f54",
            "99dbe0d2b0044f6589c2bf15436c91ad"
          ]
        },
        "outputId": "0b1f4222-0018-443e-9024-baa000ef88c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0af9916d09c45589ae56d34f9ff0be5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "METEOR:  {'meteor': np.float64(0.23826444116749992)}\n"
          ]
        }
      ]
    }
  ]
}